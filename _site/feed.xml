<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-08-01T16:39:47+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Akhila Yaragoppa</title><subtitle>A Data Science Portfolio</subtitle><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><entry><title type="html">Clearing emails from Gmail in bulk</title><link href="http://localhost:4000/apis/deleting-old-emails/" rel="alternate" type="text/html" title="Clearing emails from Gmail in bulk" /><published>2020-07-25T00:00:00+05:30</published><updated>2020-07-25T00:00:00+05:30</updated><id>http://localhost:4000/apis/deleting-old-emails</id><content type="html" xml:base="http://localhost:4000/apis/deleting-old-emails/">&lt;p&gt;A script that uses the Gmail API to delete unwanted emails.&lt;/p&gt;

&lt;h2 id=&quot;backstory&quot;&gt;Backstory&lt;/h2&gt;

&lt;p&gt;I created my Gmail account when I was 14 years old. There were about 17000 unread emails when I last checked. This made it very difficult for me to see how many new emails I had received. And all these old unread emails were simply hogging space on my Gmail account. So, one day I sought to clear all unread emails in my inbox.&lt;/p&gt;

&lt;h2 id=&quot;challenge-with-manual-deletion&quot;&gt;Challenge with manual deletion&lt;/h2&gt;

&lt;p&gt;There is no option in Gmail to delete all emails belonging to a certain category. To delete a 1000 of them manually it took me about 30 minutes. As I had decided I needed to delete these emails, I sat down and wrote a script. Which also took about 30 minutes.&lt;/p&gt;

&lt;h2 id=&quot;the-code-itself&quot;&gt;The code itself&lt;/h2&gt;

&lt;p&gt;Here is the code that did the job :)
&lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/gmail.py&quot;&gt;Source code&lt;/a&gt;&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="APIs" /><summary type="html">A script that uses the Gmail API to delete unwanted emails.</summary></entry><entry><title type="html">Harry Potter’s Invisibility Cloak</title><link href="http://localhost:4000/invisibility-cloak/" rel="alternate" type="text/html" title="Harry Potter's Invisibility Cloak" /><published>2020-07-15T00:00:00+05:30</published><updated>2020-07-15T00:00:00+05:30</updated><id>http://localhost:4000/invisibility-cloak</id><content type="html" xml:base="http://localhost:4000/invisibility-cloak/">&lt;p&gt;Take any blue cloth and be invisible.&lt;/p&gt;

&lt;h2 id=&quot;why-this-project&quot;&gt;Why this project&lt;/h2&gt;
&lt;p&gt;As a child, I always wanted to have magical powers. I came across someone on my linkedIn that did this project. I had to get myself an invisibility cloak too.&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How it Works&lt;/h2&gt;
&lt;h4 id=&quot;finding-hsv-thresholds&quot;&gt;Finding HSV thresholds&lt;/h4&gt;
&lt;p&gt;I convert the image captured by the webcam to an &lt;a href=&quot;https://en.wikipedia.org/wiki/HSL_and_HSV&quot;&gt;HSV&lt;/a&gt; image. I then set up scrollbars where I can vary the Hue, Saturation and Value to find the thresholds that detect only one color - the color of the cloak.&lt;/p&gt;
&lt;h4 id=&quot;setting-up-masks&quot;&gt;Setting up masks&lt;/h4&gt;
&lt;p&gt;I then set up masks that separate out the cloak from the rest of the picture on screen.&lt;/p&gt;
&lt;h4 id=&quot;the-trick-to-invisibility&quot;&gt;The trick to Invisibility&lt;/h4&gt;
&lt;p&gt;When webcam first starts, we capture an image of the background where the subject will be standing. When the cloak appears on screen, we superimpose the background image on the webcam display. And Voila!&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/invisibilityCloak.py&quot;&gt;Here&lt;/a&gt; is the code I wrote.&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="OpenCV" /><summary type="html">Take any blue cloth and be invisible.</summary></entry><entry><title type="html">Virtual Paint</title><link href="http://localhost:4000/virtual-paint/" rel="alternate" type="text/html" title="Virtual Paint" /><published>2020-07-08T00:00:00+05:30</published><updated>2020-07-08T00:00:00+05:30</updated><id>http://localhost:4000/virtual-paint</id><content type="html" xml:base="http://localhost:4000/virtual-paint/">&lt;p&gt;Hover a marker in the air in front of the camera to paint on the screen.&lt;/p&gt;

&lt;h2 id=&quot;why-this-project&quot;&gt;Why this project&lt;/h2&gt;
&lt;p&gt;Fascinated by the field of computer vision, I sought to learn more about it. I learnt some basics of the library of OpenCV in python. In an effort to apply the skills learnt to a project and learn more along the way, I chose this project.&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How it Works&lt;/h2&gt;
&lt;h4 id=&quot;finding-hsv-thresholds&quot;&gt;Finding HSV thresholds&lt;/h4&gt;
&lt;p&gt;I convert the image captured by the webcam to an &lt;a href=&quot;https://en.wikipedia.org/wiki/HSL_and_HSV&quot;&gt;HSV&lt;/a&gt; image. I then set up scrollbars where I can vary the Hue, Saturation and Value to find the thresholds that detect only one color.&lt;/p&gt;
&lt;h4 id=&quot;setting-up-masks&quot;&gt;Setting up masks&lt;/h4&gt;
&lt;p&gt;I then set up masks that separate out each color from the rest of the picture on screen.&lt;/p&gt;
&lt;h4 id=&quot;painting-in-the-air&quot;&gt;Painting in the air&lt;/h4&gt;
&lt;p&gt;As I move a colored marker, I draw on the image with the same color as the marker. This created the effect of a virtual marker.&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/virtualPaint.py&quot;&gt;Here&lt;/a&gt; is the code I wrote.&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="OpenCV" /><summary type="html">Hover a marker in the air in front of the camera to paint on the screen.</summary></entry><entry><title type="html">Using TensorFlow to Calculate Decision Boundaries</title><link href="http://localhost:4000/neural-nets-classification/" rel="alternate" type="text/html" title="Using TensorFlow to Calculate Decision Boundaries" /><published>2020-06-23T00:00:00+05:30</published><updated>2020-06-23T00:00:00+05:30</updated><id>http://localhost:4000/neural-nets-classification</id><content type="html" xml:base="http://localhost:4000/neural-nets-classification/">&lt;p&gt;Building neural network models using TensorFlow framework to classify objects belonging to different categories.&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/neural-nets/&quot;&gt;Data and Code&lt;/a&gt;&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="Neural Networks" /><category term="Classification" /><summary type="html">Building neural network models using TensorFlow framework to classify objects belonging to different categories.</summary></entry><entry><title type="html">Sentiment Analysis of Amazon Product Reviews</title><link href="http://localhost:4000/sentiment-analysis/" rel="alternate" type="text/html" title="Sentiment Analysis of Amazon Product Reviews" /><published>2020-06-23T00:00:00+05:30</published><updated>2020-06-23T00:00:00+05:30</updated><id>http://localhost:4000/sentiment-analysis</id><content type="html" xml:base="http://localhost:4000/sentiment-analysis/">&lt;p&gt;A classification of text-based product reviews into POSITIVE and NEGATIVE.&lt;/p&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;
&lt;p&gt;The data is collected from reviews of various books. A review given by a single user contains some text and a rating on the scale of 1-5. Text associated with 1,2 ratings is considered &lt;em&gt;negative&lt;/em&gt;, and those associated with 4,5 is considered &lt;em&gt;positive&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;data-processing&quot;&gt;Data Processing&lt;/h2&gt;
&lt;p&gt;The text data is converted into numeric vectors so that it can be passed into some classification models. The conversion from text to numerical vectors is done using ‘Bag of Words’.&lt;/p&gt;

&lt;h2 id=&quot;what-is-bag-of-words&quot;&gt;What is Bag of Words?&lt;/h2&gt;
&lt;p&gt;Bag of words simply keeps track of all the words occurring and their corresponding frequency of occurrence. Every distinct word occurring in the entire training data is assigned an index. Then a vector is formed where each entry in the vector is the number of times the word at that index occurred.&lt;/p&gt;

&lt;h2 id=&quot;classification&quot;&gt;Classification&lt;/h2&gt;
&lt;p&gt;The transformed vectors are fit using multiple classification models namely SVM, Decision Trees, Naive Bayes and Logistic Regression.&lt;/p&gt;

&lt;h2 id=&quot;prediction&quot;&gt;Prediction&lt;/h2&gt;
&lt;p&gt;This trained model is able to predict the sentiment of a new unseen text.&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;Here is the &lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/sentiment-analysis.ipynb&quot;&gt;jupyter notebook&lt;/a&gt; where I implemented the above technique.&lt;/p&gt;

&lt;h2 id=&quot;where-bag-of-words-fails&quot;&gt;Where ‘Bag of Words’ fails?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;When an unseen word that was not present in the training data is given to the model for prediction, it simple ignores that word. This word could potentially change the tone of the review, but is ignored if the machine has not seen it before.&lt;/li&gt;
  &lt;li&gt;It does not understand contextual meaning. It does not take into consideration the meaning of a word in combination with the words adjoining a given tone indicating word.
    &lt;ul&gt;
      &lt;li&gt;Ex: ‘This book was not good’ and ‘Not only was this book good, it was excellent.’ These two sentences seem similar to this model.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;It cannot comprehend that two same words can have slightly differing spellings.
    &lt;ul&gt;
      &lt;li&gt;Ex: ‘book’ and ‘books’ are two different words to this algorithm.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-is-good-about-bag-of-words-then&quot;&gt;What is good about ‘Bag of Words’ then?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The number of features generated by the model is much less compared to other state of the art techniques. This allows for use of simple classification models and quick computation.&lt;/li&gt;
  &lt;li&gt;It is a very intuitive algorithm.
    &lt;ul&gt;
      &lt;li&gt;As the complexity of algorithms in the machine learning field is increasing everyday, it can be very important to have simpler algorithms that can provide intuitive understanding for beginners, and motivate them to contribute in making the complex algorithms more intuitive.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-are-other-state-of-the-art-techniques-that-can-solve-the-same-problem&quot;&gt;What are other state of the art techniques that can solve the same problem?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Word2Vec
    &lt;ul&gt;
      &lt;li&gt;This is an algorithm that can be used to convert words to vectors.&lt;/li&gt;
      &lt;li&gt;It solves most issues in bag of words technique, such as: contextual understanding, understanding unseen words from training model.&lt;/li&gt;
      &lt;li&gt;NLTK library provides excellent support for performing this technique.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;GPT-2&lt;/li&gt;
  &lt;li&gt;GPT-3&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="NLP" /><summary type="html">A classification of text-based product reviews into POSITIVE and NEGATIVE.</summary></entry><entry><title type="html">Extracting events from Google Calendar for Data Analysis</title><link href="http://localhost:4000/apis/GoogleCalendarAnalysis/" rel="alternate" type="text/html" title="Extracting events from Google Calendar for Data Analysis" /><published>2020-01-07T00:00:00+05:30</published><updated>2020-01-07T00:00:00+05:30</updated><id>http://localhost:4000/apis/GoogleCalendarAnalysis</id><content type="html" xml:base="http://localhost:4000/apis/GoogleCalendarAnalysis/">&lt;p&gt;An effort to maximize productivity and track the progress.&lt;/p&gt;

&lt;p&gt;I wrote a python script to extract events from my google calendar using the
Google Calendar API.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Inputs: Start date, number of days (n)&lt;/li&gt;
  &lt;li&gt;Output: A csv file with events for n days and related information.
This can be directly imported as a DataFrame using pandas, for
further analysis and visualization.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;motivation&quot;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;I am always looking for ways to maximise my productivity. The goal is to
get done as much as I want to, while being careful not to reach the point of burnout.&lt;/p&gt;

&lt;p&gt;I recently came across this idea of scheduling every minute of your day using a
calendar. This method worked surprisingly well and helped me very easily achieve
my daily goals. I have been using the google calendar to track my daily activities.
It occurred to me that I could track and monitor my progress by visualizing how I
spent the last few days/weeks.&lt;/p&gt;

&lt;h1 id=&quot;what-the-code-does&quot;&gt;What the code does&lt;/h1&gt;

&lt;h2 id=&quot;querying-data-from-calendar-api&quot;&gt;Querying data from Calendar API&lt;/h2&gt;
&lt;p&gt;Each task I schedule in my day is an event. I first extract the event resources
by calling the google calendar APIs. Some useful information on how various items
in the calendar are stored, is provided in the &lt;a href=&quot;https://developers.google.com/calendar/concepts&quot;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ordering-and-segregating-data&quot;&gt;Ordering and segregating data&lt;/h2&gt;
&lt;p&gt;I segregate the events belonging to each day from the start date (configurable).
For each event I obtain:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Name of the event.&lt;/li&gt;
  &lt;li&gt;The category of the event. Each category has a different color assigned to it.&lt;/li&gt;
  &lt;li&gt;The date and time of start of the event.&lt;/li&gt;
  &lt;li&gt;The duration of the event.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;saving-data-into-a-csv&quot;&gt;Saving data into a csv&lt;/h2&gt;
&lt;p&gt;I create tables with all the above mentioned data. I save these into a csv file.
The csv file is created such that it can directly be imported into pandas as a DataFrame for further analysis.&lt;/p&gt;

&lt;h1 id=&quot;calendar-input&quot;&gt;Calendar (Input)&lt;/h1&gt;

&lt;p&gt;This is what my calendar looked like in the first week.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/g-calendar/g-calendar.png&quot; alt=&quot;Calendar image&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;extracted-data-output&quot;&gt;Extracted Data (Output)&lt;/h1&gt;

&lt;p&gt;The extracted data from google calendar has the following columns:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Day&lt;/li&gt;
  &lt;li&gt;Event name&lt;/li&gt;
  &lt;li&gt;Start datetime&lt;/li&gt;
  &lt;li&gt;Event duration&lt;/li&gt;
  &lt;li&gt;Category (Color in calendar)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A sample of the extracted data is shown below:
&lt;img src=&quot;/images/g-calendar/g-csv.png&quot; alt=&quot;csv image&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;what-to-do-with-the-extracted-csv&quot;&gt;What to do with the extracted csv&lt;/h1&gt;

&lt;p&gt;After importing the csv into a data frame, I can plot various graphs (histograms, pie charts, etc.)
indicating the amount of time spent in various activites and monitor how I utilize my time.&lt;/p&gt;

&lt;p&gt;I shall be putting up another post with the complete analysis of this data. I will
probably implement some ideas from habit tracking apps to extract useful
information and implications of this data.&lt;/p&gt;

&lt;h1 id=&quot;source-code&quot;&gt;Source Code&lt;/h1&gt;

&lt;p&gt;The source code for this project is in python. Source code can be found &lt;!---&lt;a href=&quot;/source_code/google-calendar.py&quot;&gt;here&lt;/a&gt;--&gt;
&lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/google-calendar.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="APIs" /><summary type="html">An effort to maximize productivity and track the progress.</summary></entry><entry><title type="html">Titanic - An exploratory analysis</title><link href="http://localhost:4000/titanic/" rel="alternate" type="text/html" title="Titanic - An exploratory analysis" /><published>2019-12-15T00:00:00+05:30</published><updated>2019-12-15T00:00:00+05:30</updated><id>http://localhost:4000/titanic</id><content type="html" xml:base="http://localhost:4000/titanic/">&lt;p&gt;This is an exploratory analysis of the Titanic survivors data from Kaggle.&lt;/p&gt;

&lt;p&gt;On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.&lt;/p&gt;

&lt;p&gt;While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.&lt;/p&gt;

&lt;p&gt;In this article, I will attempt to identify what category of passengers most likely survived.&lt;/p&gt;

&lt;p&gt;The features that can be examined for each passenger are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Age&lt;/li&gt;
  &lt;li&gt;Sex&lt;/li&gt;
  &lt;li&gt;Ticket class&lt;/li&gt;
  &lt;li&gt;Number of siblings / spouses aboard the Titanic&lt;/li&gt;
  &lt;li&gt;Number of parents / children aboard the Titanic&lt;/li&gt;
  &lt;li&gt;Passenger fare&lt;/li&gt;
  &lt;li&gt;Port of Embarkation&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;age&quot;&gt;Age&lt;/h2&gt;
&lt;p&gt;Let’s first have a look at the number of survivors and non-survivors among passengers of different ages.
&lt;img src=&quot;/images/titanic/age.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The following observations can be made from the graph above:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Most passengers on the ship are in the age range 15 to 50.&lt;/li&gt;
  &lt;li&gt;A high number of non-survivors exist in the age range 20-30.&lt;/li&gt;
  &lt;li&gt;There are also a good number of survivors in the same age range.&lt;/li&gt;
  &lt;li&gt;Of the 8 passengers above the age of 65, only 1 survived.&lt;br /&gt;
From the above observations, I can assume that ‘age’ can be used as a decision factor for evaluating passenger survival.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sex&quot;&gt;Sex&lt;/h2&gt;
&lt;p&gt;Let’s now see if there is a bias in number of survivors with respect to sex of the passenger.
&lt;img src=&quot;/images/titanic/male-female-survivors.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Observations from this graph:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Approximately 70% of the female passengers survived.&lt;/li&gt;
  &lt;li&gt;Only 20% of the male passengers survived.
Therefore, we can use this feature to significantly improve survival prediction of a passenger.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ticket-class&quot;&gt;Ticket Class&lt;/h2&gt;
&lt;p&gt;Next, let’s see how the ticket class affected the survival chances of a passenger:&lt;br /&gt;
&lt;img src=&quot;/images/titanic/Pclass.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Observations from this graph:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;More than 50% of passengers with Class 1 tickets survived.&lt;/li&gt;
  &lt;li&gt;Around 50% of passengers with Class 2 tickets survived.&lt;/li&gt;
  &lt;li&gt;Only around 30% of passengers with Class 3 tickets survived.
This tells us that somehow even during a life/death situation like the sinking of the Titanic, people with better tickets had a higher chance of survival.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ticket-fare&quot;&gt;Ticket Fare&lt;/h2&gt;
&lt;p&gt;Another graph on similar lines as the ticket class, is the graph of ticket fare.&lt;br /&gt;
&lt;img src=&quot;/images/titanic/fare.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
From the above graph, we can see that only 4 people that did not survive, paid a ticket fare above 100. Also, from the graph of non-survivors, we see that a very high number of non-survivors are concentrated around low ticket prices.&lt;br /&gt;
We see that this graph affects the survival in the same way that the ticket class did. It is possible that most information given by this variable is redundant. If this were a huge dataset with many features, we could possibly ignore this feature, or generate a new feature from the ‘ticket class’ and the ‘ticket fare’.&lt;/p&gt;

&lt;h2 id=&quot;port-of-embarkation&quot;&gt;Port of embarkation&lt;/h2&gt;

&lt;h3 id=&quot;titanic-sailing-route-map&quot;&gt;Titanic sailing route map&lt;/h3&gt;
&lt;p&gt;Titanic first arrived at Southampton, UK.&lt;br /&gt;
6 days later, Titanic arrived at Cherbourg, France.&lt;br /&gt;
Titanic arrived in Queenstown, Ireland a day later.&lt;br /&gt;
3 days later Titanic hits the iceberg.&lt;/p&gt;

&lt;p&gt;Let’s look at a graph of the survival variation based on the ‘port of embarkation’.&lt;br /&gt;
&lt;img src=&quot;/images/titanic/embarkation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Observations:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A huge number of people boarded from Southampton. This was probably because it was the first port where people boarded.&lt;/li&gt;
  &lt;li&gt;Only about 30% of the passengers who boarded in Southampton survived.&lt;/li&gt;
  &lt;li&gt;A small number of people boarded in Queenstown, and about 40% of them survived.&lt;/li&gt;
  &lt;li&gt;In Cherbourg, more than 50% of the passengers survived.  This was probably because most passengers who boarded in Cherbourg had class 1 tickets.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This analysis gives us a fair idea of what factors most determined the survival of a passenger aboard the titanic. These features can be used to build machine learning models to predict the survival of a passenger. A preliminary knowledge of the data sets a much required context to tweak the features as necessary for building efficient machine learning models.&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;The above analysis was carried out using a jupyter notebook. The notebook can be found &lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/Titanic-Data-Visualization.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="Data Visualization" /><summary type="html">This is an exploratory analysis of the Titanic survivors data from Kaggle.</summary></entry><entry><title type="html">Cosine distance between two documents</title><link href="http://localhost:4000/algorithms/document-distance/" rel="alternate" type="text/html" title="Cosine distance between two documents" /><published>2019-12-10T00:00:00+05:30</published><updated>2019-12-10T00:00:00+05:30</updated><id>http://localhost:4000/algorithms/document-distance</id><content type="html" xml:base="http://localhost:4000/algorithms/document-distance/">&lt;p&gt;A tiny python script that calculates the cosine distance between any two documents.&lt;/p&gt;

&lt;h2 id=&quot;what-is-cosine-distance&quot;&gt;What is cosine distance?&lt;/h2&gt;

&lt;p&gt;In simple terms, cosine distance gives an idea of the degree of dissimilarity between two sets of text documents. We do this by calculating the angle between them. Angle between two vectors is the angle formed by the word vectors in the two documents. A detailed explanation of the algorithm should make this clear.&lt;/p&gt;

&lt;h2 id=&quot;where-can-we-see-this-being-used&quot;&gt;Where can we see this being used?&lt;/h2&gt;

&lt;p&gt;There are several applications of cosine distance algorithm.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Implementing a search engine&lt;/li&gt;
  &lt;li&gt;Testing for plagiarism&lt;/li&gt;
  &lt;li&gt;Natural Language Processing&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;p&gt;Steps:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Parse the given document to find all the words present in the document&lt;/li&gt;
  &lt;li&gt;Calculate frequencies of each word. Consider this a multi-dimensional vector (the number of dimensions of the vector being the number of unique words in the document)&lt;/li&gt;
  &lt;li&gt;Calculate the angle between these two vectors&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;inputs&quot;&gt;Inputs&lt;/h2&gt;

&lt;p&gt;The code takes two file names as input, between which you intend to calculate the angle.&lt;/p&gt;

&lt;h2 id=&quot;output&quot;&gt;Output&lt;/h2&gt;

&lt;p&gt;The final output is the angle (in radians) between the two documents.&lt;/p&gt;

&lt;h2 id=&quot;source-code&quot;&gt;Source code&lt;/h2&gt;

&lt;p&gt;The source code with the entire implementation can be found &lt;a href=&quot;https://github.com/akhilayaragoppa/akhilayaragoppa.github.io/blob/master/source_code/document-distance.py&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="Algorithms" /><summary type="html">A tiny python script that calculates the cosine distance between any two documents.</summary></entry><entry><title type="html">An Analysis of Course Feedback Forms</title><link href="http://localhost:4000/feedback-forms/" rel="alternate" type="text/html" title="An Analysis of Course Feedback Forms" /><published>2015-11-30T00:00:00+05:30</published><updated>2015-11-30T00:00:00+05:30</updated><id>http://localhost:4000/feedback-forms</id><content type="html" xml:base="http://localhost:4000/feedback-forms/">&lt;p&gt;An analysis of course feedback forms to predict the instructor, students attendance and number of repeats for that course.&lt;/p&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;

&lt;p&gt;The data is a collection of course feedback forms from a group of 5820 students, along with the attendance, number of repeats, and the difficulty level of the course for which the feedback has been submitted.&lt;/p&gt;

&lt;p&gt;The data has four sets of classes that it can be classified into –&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Instructor (1, 2, 3)&lt;/li&gt;
  &lt;li&gt;No. of repeats (1, 2, 3)&lt;/li&gt;
  &lt;li&gt;Attendance (0, 1, 2, 3, 4)&lt;/li&gt;
  &lt;li&gt;Difficulty (1, 2, 3, 4, 5)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are 28 features in all, each one being a rating on a scale of 1 to 5 of some aspect of the course or the instructor.&lt;/p&gt;

&lt;p&gt;I tried feeding the features into a neural network, and based on the feedback of a random student I tried to predict –&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the number of repeats&lt;/li&gt;
  &lt;li&gt;the attendance of a student&lt;/li&gt;
  &lt;li&gt;the instructor&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;neural-network&quot;&gt;Neural network&lt;/h2&gt;

&lt;p&gt;I used a two-layer feed-forward network, with sigmoid hidden and softmax output neurons. This can classify vectors arbitrarily well, given that there are enough neurons in its hidden layer.&lt;/p&gt;

&lt;h2 id=&quot;predicting-the-number-of-repeats&quot;&gt;Predicting the number of repeats&lt;/h2&gt;
&lt;p&gt;I first trained the network to predict the no. of repeats. I got a very high accuracy of ~80%. On closer observation, I found that due to the highly biased distribution of the data points in one class (0 repeats), the network predicted almost every point as belonging to that class.
&lt;img src=&quot;/images/feedback/bar-1.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/feedback/mat-1.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;predicting-the-attendance&quot;&gt;Predicting the attendance&lt;/h2&gt;
&lt;p&gt;I then tried to train the network to predict the attendance. The attendance histogram had a better distribution than the previous case. But, I only managed to get an accuracy of about 37% with the validation data. This probably happened because the number of possible classes increased to 5.
&lt;img src=&quot;/images/feedback/bar-2.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/feedback/mat-2.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;predicting-the-instructor&quot;&gt;Predicting the instructor&lt;/h2&gt;
&lt;p&gt;Finally, I trained the network to predict the instructor for a given set of feedback values. There were only 3 instructors, and the distribution looked like this.
&lt;img src=&quot;/images/feedback/bar-3.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/feedback/mat-3.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;varying-the-number-of-neurons-to-increase-prediction-accuracy&quot;&gt;Varying the number of neurons to increase prediction accuracy&lt;/h3&gt;
&lt;p&gt;With 10 neurons in the hidden layer, I obtained an accuracy of 59% for the validation data. Similarly, for 5 and 20 neurons in the hidden layer, I got accuracies of 62.4% and 62.8% respectively.&lt;/p&gt;

&lt;h3 id=&quot;varying-the-number-of-iterations-for-better-performance&quot;&gt;Varying the number of iterations for better performance&lt;/h3&gt;
&lt;p&gt;At the 37th iteration, I obtained the best validation performance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/feedback/validation.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="Neural Networks" /><summary type="html">An analysis of course feedback forms to predict the instructor, students attendance and number of repeats for that course.</summary></entry><entry><title type="html">Classification of Songs - Million Song Dataset</title><link href="http://localhost:4000/million-song-dataset/" rel="alternate" type="text/html" title="Classification of Songs - Million Song Dataset" /><published>2015-09-15T00:00:00+05:30</published><updated>2015-09-15T00:00:00+05:30</updated><id>http://localhost:4000/million-song-dataset</id><content type="html" xml:base="http://localhost:4000/million-song-dataset/">&lt;p&gt;An analysis of the properties of a song to identify the decade to which the song belonged.&lt;/p&gt;

&lt;h2 id=&quot;dataset&quot;&gt;Dataset&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Million Song Dataset&lt;/strong&gt; is a freely-available collection of audio features and metadata for a million contemporary popular music tracks. This project uses a &lt;a href=&quot;http://millionsongdataset.com/pages/getting-dataset/#subset&quot;&gt;subset&lt;/a&gt; of this dataset. The data contains 515,345 songs, each described by 90 features, and the year in which the song was released. The years range from 1922 to 2011.&lt;/p&gt;

&lt;h2 id=&quot;exploratory-data-analysis&quot;&gt;Exploratory Data Analysis&lt;/h2&gt;

&lt;p&gt;For simplicity, the number of classes is reduced from 90 to 9 by assigning a decade to each song, instead of year.
A histogram of the count of songs in each decade showed an unevenly distributed data:
&lt;img src=&quot;http://localhost:4000/images/hist-unmodified.PNG&quot; alt=&quot;Hist-unmodified&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In an attempt to obtain a more evenly distributed data, the width of the classes was altered, thus resulting in a distribution as shown below:
&lt;img src=&quot;/images/hist-modified.PNG&quot; alt=&quot;hist-modified&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;choosing-features&quot;&gt;Choosing Features&lt;/h2&gt;
&lt;p&gt;A feature can be chosen for classification, if it peaks at different places for different classes. For example, I chose ‘Timbre average 1’ as one of the classifiers as it peaked at various regions for Class 1 and Class 2 as shown in the below figure:
&lt;img src=&quot;/images/hist-f1-c1-c2.PNG&quot; alt=&quot;hist-f1-c1-c2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;principal-components&quot;&gt;Principal Components&lt;/h3&gt;
&lt;p&gt;A scatter plot of the first two principal components looked something like this:
&lt;img src=&quot;/images/scatter-pc.PNG&quot; alt=&quot;scatter-pc&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Two important observations can be made from this plot:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;There is a significant difference in the amount of data between the first few classes and the last couple of classes (it is obscured by pink).&lt;/li&gt;
  &lt;li&gt;The colors are all bundled together. Ideally, the different colors must be local to different regions on the plot, so that a more accurate decision can be made when predicting the class of some unknown data.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bayes-classification&quot;&gt;Bayes’ Classification&lt;/h2&gt;
&lt;p&gt;The test data was first classified without reducing any dimensions (i.e., using all 90 features independently). An accuracy of 22% was obtained.&lt;/p&gt;

&lt;p&gt;The 90 features were then projected in the direction of the 2 eigenvectors corresponding to the 2 highest eigenvalues. Classifying with the help of the 2 principal components returned an accuracy of around 50%. As this result seemed odd, the procedure was rechecked.
This lead to a conclusion that the dataset has the &lt;strong&gt;curse of dimesionality&lt;/strong&gt;. The problem is that when the dimensionality increases, the volume of the space increases so fast that the available data becomes sparse. So, a huge amount of data is required to support analysis in higher dimensions.&lt;/p&gt;

&lt;p&gt;After modyfying class sizes to obtain a more evenly distributed data, the prediction accuracy was in fact lower (only about 35%). I do not have a plausible explanation for this. The decision boundary looks as below:
&lt;img src=&quot;/images/dec-bound.PNG&quot; alt=&quot;decision-boundary&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;The MATLAB code written to perform the above analysis:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'YearPredictionMSD.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;91&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%Separate data for train and test as given in website&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%separate class info from data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;463715&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;class_traingData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;463715&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r_class_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ClassReduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_traingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;testingData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;463716&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;515345&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;class_testingData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;463716&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;515345&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r_class_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ClassReduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;%histogram of two features&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;% find 2 principle components(PC)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coeff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coeff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coeff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;%figure, mesh(coeff);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;% finding data representation along PC&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lowrep_trainingData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lowrep_trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coeff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dim_cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowrep_trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lowrep_testingData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lowrep_testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coeff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NaiveBayes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_class_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_op&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_class_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NaiveBayes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowrep_trainingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_class_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_op1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowrep_testingData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_op1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_class_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acuracy1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Akhila Yaragoppa</name><email>akhila171@gmail.com</email></author><category term="Classification" /><summary type="html">An analysis of the properties of a song to identify the decade to which the song belonged.</summary></entry></feed>